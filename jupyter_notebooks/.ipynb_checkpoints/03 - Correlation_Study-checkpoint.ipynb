{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Correlation Study Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1: \n",
        "  * The client is interested in discovering how the house attributes correlate with the sale price.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement 1 and can be used to build Streamlit App\n",
        "* Save plots in folder for documentation\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* The size of a property matters. Higher values of 1stFlrSF, GarageArea, GrLivArea, MasVnrArea, OpenPorchSF and TotalBsmtSF are associated with higher sale price.\n",
        "* Time matters. Recently built houses, and houses with recently built garages and recently added remodel have higher sale prices.  \n",
        "* Quality matters. Houses with higher overall quality and kitchen quality ratings have higher sale prices. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/cleaned/HousePricesCleaned.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start with data profiling report so that we get more familiar with the content of the dataset. We check variable type and distribution, missing levels and how each variable may related to our target.\n",
        "\n",
        "* We import pandas_profiling library and generate a profile report of our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above report reveals that\n",
        "\n",
        "* Nine features have missing values.\n",
        "* EnclosedPorch and WoodDeckSF have 90.7% and 89.4% missing values respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Correlation and PPS Analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our dataset has four categorical variables that are of object data type. So we need to encode them so that we can use them to calculate correlation coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now our dataset has 37 columns, because the categorical variables have been encoded and their categories converted to separate columns with binary values (0 0r 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next, we define functions that will calculate the correlations, create heatmaps and display them.\n",
        "* We save each heatmap to docs directory for later use in the documentation of this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ppscore as pps\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  \"\"\"\n",
        "  Function to create heatmap using correlations.\n",
        "  \"\"\"\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "     # Save heatmaps to docs folder\n",
        "    if df.name == \"corr_spearman\":\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_spearman.png', bbox_inches='tight')\n",
        "    else:\n",
        "      plt.savefig(f'docs/plots/heatmap_corr_pearson.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    \"\"\"\n",
        "    Function to create heatmap using pps.\n",
        "    \"\"\"\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      # Save heatmap to docs folder\n",
        "      plt.savefig(f'docs/plots/heatmap_pps.png', bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  \"\"\"\n",
        "  Function to calculate correlations and pps.\n",
        "  \"\"\"\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_spearman.name = 'corr_spearman'\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "  df_corr_pearson.name = 'corr_pearson'\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "  \"\"\"\n",
        "  Function to display the correlations and pps.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In the following cell, we call the function that calculates the correlations and pps.\n",
        "* This function invokes the .corr() method where we pass spearman and pearson to evaluate the linear and monotonic relationships respectively between the features and the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Then we display the correlations and pps by calling the DisplayCorrAndPPS function we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* When we calculate the correlations with the .corr() method, the return value is a pandas series, and the first item is the correlation between SalePrice and SalePrice. \n",
        "* As this correlation is 1 and carries no information, we use [1:] to exclude it from the series.\n",
        "* Now we sort the remaining values considering the aboslute value, which is done by setting key=abs\n",
        "\n",
        "* We know from the heatmaps above that the number of features that have correlations above the threshold of 0.4 is less than 10. So we show the first 10 values of each series below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Let's merge the pearson and spearman correlations. We use set to avoid duplication of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the correlation study results, we will focus on the following variables and their relationship to house sale prices.\n",
        "* 1stFlrSF\n",
        "* GarageArea\n",
        "* GrLivArea\n",
        "* KitchenQual\n",
        "* MasVnrArea\n",
        "* OpenPorchSF\n",
        "* OverallQual\n",
        "* TotalBsmtSF\n",
        "* YearBuilt\n",
        "* YearRemodAdd\n",
        "\n",
        "* These features reflect the relevance and potential predictive power of the size of a property, the quality of a house and whether the property has been built or remodeled recently or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['1stFlrSF', 'GarageArea', 'GrLivArea', 'KitchenQual', 'MasVnrArea', 'OpenPorchSF', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA on selected variables\n",
        "\n",
        "* Now we do exploratory data analysis using the features that have moderate or high correlation with out target, SalePrice.\n",
        "\n",
        "* We create a separate DataFrame for the EDA by adding SalePrice so that we can use data visualization to draw insights about the relationship between each feature and the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df.filter(vars_to_study + ['SalePrice'])\n",
        "df_eda.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Target Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distribution of Sales Price\n",
        "\n",
        "* First, we plot the target variable, SalePrice, in a histogram to have an idea of its distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style('whitegrid')\n",
        "target_var = 'SalePrice'\n",
        "time = ['YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "def plot_target_hist(df, target_var):\n",
        "  \"\"\"\n",
        "  Function to plot a histogram of the target and\n",
        "  save the figure to folder.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  sns.histplot(data=df, x=target_var, kde=True)\n",
        "  plt.title(f\"Distribution of {target_var}\", fontsize=20)\n",
        "  plt.savefig(f'docs/plots/hist_plot_{target_var}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "plot_target_hist(df, target_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As we note from the histogram above, the target variable is silightly skewed to the right. Some houses have very high sale prices, much higher that the typical property."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bivariate plots\n",
        "\n",
        "* In this exercise, We are interested in answering business requirement 1, which is 'discovering how the house attributes correlate with the sale price.'\n",
        "\n",
        "* So we plot sale price in relation to both numerical and categorical features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lm(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Function to create linear regression plots of the target and\n",
        "  features with continuous values.\n",
        "  It saves each figure to folder.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  sns.lmplot(data=df, x=col, y=target_var, ci=None)\n",
        "  plt.title(f\"{col}\", fontsize=20)\n",
        "  plt.savefig(f'docs/plots/lm_plot_price_by_{col}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "def plot_line(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Function to create a line plot of the target and\n",
        "  time variables (years).\n",
        "  It saves each figure to folder.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  sns.lineplot(data=df, x=col, y=target_var)\n",
        "  plt.title(f\"{col}\", fontsize=20)\n",
        "  plt.savefig(f'docs/plots/line_plot_price_by_{col}.png', bbox_inches='tight')        \n",
        "  plt.show()\n",
        "\n",
        "def plot_box(df, col, target_var):\n",
        "  \"\"\"\n",
        "  Function to create a box plot of the target and\n",
        "  categorical variables.\n",
        "  It saves each figure to folder.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.boxplot(data=df, x=col, y=target_var) \n",
        "  plt.title(f\"{col}\", fontsize=20)\n",
        "  plt.savefig(f'docs/plots/box_plot_price_by_{col}', bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "for col in vars_to_study:\n",
        "  if len(df_eda[col].unique()) <= 10:\n",
        "    plot_box(df_eda, col, target_var)\n",
        "    print(\"\\n\\n\")\n",
        "  else:\n",
        "    if col in time:\n",
        "      plot_line(df_eda, col, target_var)\n",
        "      print(\"\\n\\n\")\n",
        "    else:\n",
        "      plot_lm(df_eda, col, target_var)\n",
        "      print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the plots, we note that higher values of the features tend to be associated with higher property value. This is true for the linear regression plots, box plots as well as line plots (time variables). \n",
        "\n",
        "* Similar to the observation we made about the distribution of the target having extreme values, there seem to be outliers in the features as well.\n",
        "\n",
        "* We will handle outliers in the feature engineering notebook to make the data good for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We make the following observations from both the correlation analyses and the plots.\n",
        "\n",
        "* The size of a property matters. Higher values of 1stFlrSF, GarageArea, GrLivArea, MasVnrArea, OpenPorchSF and TotalBsmtSF are associated with higher sale price.\n",
        "* Time matters. Recently built houses, and houses with recently built garages and recently added remodel have higher sale prices.  \n",
        "* Quality matters. Houses with higher overall quality and kitchen quality ratings have higher sale prices. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
