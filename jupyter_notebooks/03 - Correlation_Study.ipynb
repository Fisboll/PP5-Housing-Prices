{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Correlation Study Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Answer business requirement 1: \n",
    "  * The client is interested in discovering how the house attributes correlate with the sale price.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate code that answers business requirement 1 and can be used to build Streamlit App\n",
    "* Save plots in folder for documentation\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* The size of a property matters. Higher values of 1stFlrSF, GarageArea, GrLivArea, MasVnrArea, OpenPorchSF and TotalBsmtSF are associated with higher sale price.\n",
    "* Time matters. Recently built houses, and houses with recently built garages and recently added remodel have higher sale prices.  \n",
    "* Quality matters. Houses with higher overall quality and kitchen quality ratings have higher sale prices. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/PP5-Housing-Prices/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/PP5-Housing-Prices'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/datasets/cleaned/HousePricesCleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutputs/datasets/cleaned/HousePricesCleaned.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/datasets/cleaned/HousePricesCleaned.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"outputs/datasets/cleaned/HousePricesCleaned.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with data profiling report so that we get more familiar with the content of the dataset. We check variable type and distribution, missing levels and how each variable may related to our target.\n",
    "\n",
    "* We import pandas_profiling library and generate a profile report of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=df, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above report reveals that\n",
    "\n",
    "* Nine features have missing values.\n",
    "* EnclosedPorch and WoodDeckSF have 90.7% and 89.4% missing values respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "## Correlation and PPS Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has four categorical variables that are of object data type. So we need to encode them so that we can use them to calculate correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OneHotEncoder\n",
    "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
    "df_ohe = encoder.fit_transform(df)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now our dataset has 37 columns, because the categorical variables have been encoded and their categories converted to separate columns with binary values (0 0r 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we define functions that will calculate the correlations, create heatmaps and display them.\n",
    "* We save each heatmap to docs directory for later use in the documentation of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
    "  \"\"\"\n",
    "  Function to create heatmap using correlations.\n",
    "  \"\"\"\n",
    "  if len(df.columns) > 1:\n",
    "    mask = np.zeros_like(df, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    mask[abs(df) < threshold] = True\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                linewidth=0.5\n",
    "                     )\n",
    "    axes.set_yticklabels(df.columns, rotation = 0)\n",
    "    plt.ylim(len(df.columns),0)\n",
    "     # Save heatmaps to docs folder\n",
    "    if df.name == \"corr_spearman\":\n",
    "      plt.savefig(f'docs/plots/heatmap_corr_spearman.png', bbox_inches='tight')\n",
    "    else:\n",
    "      plt.savefig(f'docs/plots/heatmap_corr_pearson.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
    "    \"\"\"\n",
    "    Function to create heatmap using pps.\n",
    "    \"\"\"\n",
    "    if len(df.columns) > 1:\n",
    "\n",
    "      mask = np.zeros_like(df, dtype=np.bool)\n",
    "      mask[abs(df) < threshold] = True\n",
    "\n",
    "      fig, ax = plt.subplots(figsize=figsize)\n",
    "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
    "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                       linewidth=0.05,linecolor='grey')\n",
    "      \n",
    "      plt.ylim(len(df.columns),0)\n",
    "      # Save heatmap to docs folder\n",
    "      plt.savefig(f'docs/plots/heatmap_pps.png', bbox_inches='tight')\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "  \"\"\"\n",
    "  Function to calculate correlations and pps.\n",
    "  \"\"\"\n",
    "  df_corr_spearman = df.corr(method=\"spearman\")\n",
    "  df_corr_spearman.name = 'corr_spearman'\n",
    "  df_corr_pearson = df.corr(method=\"pearson\")\n",
    "  df_corr_pearson.name = 'corr_pearson'\n",
    "\n",
    "  pps_matrix_raw = pps.matrix(df)\n",
    "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "  print(pps_score_stats.round(3))\n",
    "\n",
    "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
    "                      figsize=(20,12), font_annot=8 ):\n",
    "  \"\"\"\n",
    "  Function to display the correlations and pps.\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "  print(\"* Analyze multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "  print(\"It evaluates monotonic relationship \\n\")\n",
    "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the following cell, we call the function that calculates the correlations and pps.\n",
    "* This function invokes the .corr() method where we pass spearman and pearson to evaluate the linear and monotonic relationships respectively between the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then we display the correlations and pps by calling the DisplayCorrAndPPS function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
    "                  figsize=(12,10), font_annot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we calculate the correlations with the .corr() method, the return value is a pandas series, and the first item is the correlation between SalePrice and SalePrice. \n",
    "* As this correlation is 1 and carries no information, we use [1:] to exclude it from the series.\n",
    "* Now we sort the remaining values considering the aboslute value, which is done by setting key=abs\n",
    "\n",
    "* We know from the heatmaps above that the number of features that have correlations above the threshold of 0.4 is less than 10. So we show the first 10 values of each series below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
    "corr_pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's merge the pearson and spearman correlations. We use set to avoid duplication of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the correlation study results, we will focus on the following variables and their relationship to house sale prices.\n",
    "* 1stFlrSF\n",
    "* GarageArea\n",
    "* GrLivArea\n",
    "* KitchenQual\n",
    "* MasVnrArea\n",
    "* OpenPorchSF\n",
    "* OverallQual\n",
    "* TotalBsmtSF\n",
    "* YearBuilt\n",
    "* YearRemodAdd\n",
    "\n",
    "* These features reflect the relevance and potential predictive power of the size of a property, the quality of a house and whether the property has been built or remodeled recently or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_study = ['1stFlrSF', 'GarageArea', 'GrLivArea', 'KitchenQual', 'MasVnrArea', 'OpenPorchSF', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\n",
    "vars_to_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on selected variables\n",
    "\n",
    "* Now we do exploratory data analysis using the features that have moderate or high correlation with out target, SalePrice.\n",
    "\n",
    "* We create a separate DataFrame for the EDA by adding SalePrice so that we can use data visualization to draw insights about the relationship between each feature and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.filter(vars_to_study + ['SalePrice'])\n",
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Sales Price\n",
    "\n",
    "* First, we plot the target variable, SalePrice, in a histogram to have an idea of its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "target_var = 'SalePrice'\n",
    "time = ['YearBuilt', 'YearRemodAdd']\n",
    "\n",
    "def plot_target_hist(df, target_var):\n",
    "  \"\"\"\n",
    "  Function to plot a histogram of the target and\n",
    "  save the figure to folder.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  sns.histplot(data=df, x=target_var, kde=True)\n",
    "  plt.title(f\"Distribution of {target_var}\", fontsize=20)\n",
    "  plt.savefig(f'docs/plots/hist_plot_{target_var}.png', bbox_inches='tight')        \n",
    "  plt.show()\n",
    "\n",
    "plot_target_hist(df, target_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we note from the histogram above, the target variable is silightly skewed to the right. Some houses have very high sale prices, much higher that the typical property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate plots\n",
    "\n",
    "* In this exercise, We are interested in answering business requirement 1, which is 'discovering how the house attributes correlate with the sale price.'\n",
    "\n",
    "* So we plot sale price in relation to both numerical and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lm(df, col, target_var):\n",
    "  \"\"\"\n",
    "  Function to create linear regression plots of the target and\n",
    "  features with continuous values.\n",
    "  It saves each figure to folder.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  sns.lmplot(data=df, x=col, y=target_var, ci=None)\n",
    "  plt.title(f\"{col}\", fontsize=20)\n",
    "  plt.savefig(f'docs/plots/lm_plot_price_by_{col}.png', bbox_inches='tight')        \n",
    "  plt.show()\n",
    "\n",
    "def plot_line(df, col, target_var):\n",
    "  \"\"\"\n",
    "  Function to create a line plot of the target and\n",
    "  time variables (years).\n",
    "  It saves each figure to folder.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  sns.lineplot(data=df, x=col, y=target_var)\n",
    "  plt.title(f\"{col}\", fontsize=20)\n",
    "  plt.savefig(f'docs/plots/line_plot_price_by_{col}.png', bbox_inches='tight')        \n",
    "  plt.show()\n",
    "\n",
    "def plot_box(df, col, target_var):\n",
    "  \"\"\"\n",
    "  Function to create a box plot of the target and\n",
    "  categorical variables.\n",
    "  It saves each figure to folder.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  sns.boxplot(data=df, x=col, y=target_var) \n",
    "  plt.title(f\"{col}\", fontsize=20)\n",
    "  plt.savefig(f'docs/plots/box_plot_price_by_{col}', bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "for col in vars_to_study:\n",
    "  if len(df_eda[col].unique()) <= 10:\n",
    "    plot_box(df_eda, col, target_var)\n",
    "    print(\"\\n\\n\")\n",
    "  else:\n",
    "    if col in time:\n",
    "      plot_line(df_eda, col, target_var)\n",
    "      print(\"\\n\\n\")\n",
    "    else:\n",
    "      plot_lm(df_eda, col, target_var)\n",
    "      print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we note that higher values of the features tend to be associated with higher property value. This is true for the linear regression plots, box plots as well as line plots (time variables). \n",
    "\n",
    "* Similar to the observation we made about the distribution of the target having extreme values, there seem to be outliers in the features as well.\n",
    "\n",
    "* We will handle outliers in the feature engineering notebook to make the data good for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Conclusions and Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the following observations from both the correlation analyses and the plots.\n",
    "\n",
    "* The size of a property matters. Higher values of 1stFlrSF, GarageArea, GrLivArea, MasVnrArea, OpenPorchSF and TotalBsmtSF are associated with higher sale price.\n",
    "* Time matters. Recently built houses, and houses with recently built garages and recently added remodel have higher sale prices.  \n",
    "* Quality matters. Houses with higher overall quality and kitchen quality ratings have higher sale prices. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
